#version 430 core
#extension GL_EXT_shader_image_load_store : enable
#define M_PI 3.14159265358979323846

#define RENDER_MODE_0 //PATH TRACING
//#define RENDER_MODE_1 //METROPLIS
//#define RENDER_MODE_2 //BIDIRECTIONAL
//#define RENDER_MODE_3 // NEXT EVENT ESTIMATION (NEE)

/******************************************************************************
╔════════════════════════════════════════════════════════════════════════════╗
║                 METROPOLIS LIGHT TRANSPORT COMPUTE SHADER                  ║
║                                                                            ║
║ This shader implements a Metropolis Light Transport (MLT) algorithm for    ║
║ path-traced image synthesis. It leverages compute shaders with image       ║
║ load/store and atomic operations to progressively accumulate samples       ║
║ across frames.                                                             ║
║                                                                            ║
║ Key features:                                                              ║
║   - Multiple ray bounces per sample                                        ║
║   - Metropolis mutation loop with lens perturbation                        ║
║   - Weighted per-pixel averaging with atomic counters                      ║
║   - BVH traversal for scene geometry                                       ║
║   - Supports bidirectional light transport                                 ║
║   - Realistic material shading with albedo and translucent materials       ║
║   - Comprehensive debugging tools and tone mapping                         ║
╚════════════════════════════════════════════════════════════════════════════╝
********************************************************************************/


///////////////////////////////
//        STRUCTURES         //
///////////////////////////////

// Material properties for shading
struct Material {
    vec3 emmisionColor;       // Emission color
    float emmisionStrength;    // Emission strength (intensity)
    vec3 diffuseColor;        // Diffuse reflectance
    float smoothness;          // Surface smoothness (specular)
    vec3 specularColor;       // Specular reflectance
    float specularProbability; // Probability of specular reflection (called specularChance in C++)

    int textureSlot;          // Texture slot index
    float refractiveIndex;    // Add refractive index for translucent materials
    int isTranslucent;       // Flag for translucent materials
};

struct MutationResults {
    vec2 uv;
    int large;
};
// Model instance with BVH node offsets and material
struct Model {
    Material material;
    int NodeOffset;
    int TriangleOffset;
    float HasNorm;
};

// Sphere primitive
struct Sphere {
    Material material;
    vec3 position;
    vec3 radius;  // Use the x component as the radius
};

// Debug box primitive
struct DebugBox {
    Material material;
    vec3 position;
    vec3 size;
};

// Triangle primitive for mesh intersections
struct Triangle {
    vec3 posA, posB, posC;
    vec3 normA, normB, normC;
    vec2 uvA, uvB, uvC, uvD;
};

// Mesh info (bounding box, material, triangle indices)
struct MeshInfo {
    vec3 boundsMin;
    vec3 boundsMax;
    Material material;
    uint firstTriangleIndex;
    uint numTriangles;
    vec2 padding;
};

// Camera parameters
struct Camera {
    vec3 position;
    vec3 direction;
    vec3 fov; // Field-of-view (in degrees)
};

// Ray definition (origin and direction)
struct Ray {
    vec3 origin;
    vec3 direction;
};

// Information about a ray-scene intersection
struct HitInfo {
    vec3 hitPoint;
    vec3 normal;
    vec3 albedo;
    bool didHit;
    float dst;
    Material material;
    int objIndex;
    int type; //sphere = 0, triangle = 1
};

// BVH node used for acceleration structure
struct BVHNode {
    vec3 minBounds;
    vec3 maxBounds;
    float p2;
    int triangleStartIndex;
    int triangleCount;
    int childIndex; // -1 indicates a leaf node
};

///////////////////////////////
//   SHADER LAYOUT & BUFFERS //
///////////////////////////////

// Work group dimensions
#define LOCAL_SIZE_X 8
#define LOCAL_SIZE_Y 8

layout(local_size_x = LOCAL_SIZE_X, local_size_y = LOCAL_SIZE_Y, local_size_z = 1) in;

//======================================================================
// Image outputs
//======================================================================
// Binding 0: Primary output image (float color, RGBA32F). The final 
// rendered image is written here.
layout(rgba32f, binding = 0) uniform image2D screen;       

// Binding 1: Average screen image. This buffer stores per-pixel sample 
// counters or running averages for progressive accumulation.
layout(rgba32f, binding = 1) uniform image2D averageScreen;   

// Binding 2: Old screen image. Contains the previous frame's image data 
// used for accumulation.
layout(rgba32f, binding = 2) uniform image2D oldScreen;      

// Binding 5: MetroSample image. Used to store the colors generated during 
// metropolis sampling.
layout(rgba32f, binding = 5) uniform image2D metroSample; 

// Binding 6: MetroDir image. Stores the directional information (e.g. 
// sampling directions) for metropolis mutations.
layout(rgba32f, binding = 6) uniform image2D metroDir; 

//======================================================================
// Global scene and camera data
//======================================================================
// Binding 3: Buffer containing the camera data (position, direction, FOV, etc.).
layout(std430, binding = 3) buffer CameraData {
    Camera camera;
};

// Binding 4: Buffer containing the current frame number.
layout(std430, binding = 4) buffer Frames {
    double Frame;
};

//======================================================================
// Scene primitives buffers
//======================================================================
// Binding 7: Buffer containing sphere data (for circular objects).
layout(std430, binding = 7) buffer CircleData {
    Sphere spheres[];
};

// Binding 8: Buffer holding the count of spheres.
layout(std430, binding = 8) buffer CircleLength {
    uint NumSpheres;
};

// Binding 9: Buffer containing triangle data for mesh intersections.
layout(std430, binding = 9) buffer TriangleData {
    Triangle Triangles[];
};

// Binding 10: Buffer mapping each triangle to its corresponding mesh index.
layout(std430, binding = 10) buffer TriangleToMeshMap {
    int triangleToMeshMap[];
};

// Binding 11: Buffer containing BVH nodes used for accelerating ray traversal.
layout(std430, binding = 11) buffer BVHNodes {
    BVHNode nodes[];
};

// Binding 12: Buffer holding the number of BVH nodes.
layout(std430, binding = 12) buffer NodeLength {
    uint NumNodes;
};

// Binding 13: Buffer containing model data (mesh instances) for the scene.
layout(std430, binding = 13) buffer _Models {
    Model Models[];
};

// Binding 14: Buffer holding the number of models.
layout(std430, binding = 14) buffer ModelLength {
    uint NumModels;
};

//======================================================================
// BVH Stack Buffer
//======================================================================
// Binding 20: Per-thread buffer used as a stack during BVH traversal.
// This buffer holds the indices of BVH nodes as the traversal proceeds.
layout(std430, binding = 20) buffer BVHStackBuffer {
    int bvhStack[];
};

const int MAX_STACK_SIZE = 32;

///////////////////////////////
//         UNIFORMS        //
///////////////////////////////
uniform sampler2DArray diffuseTextures;

uniform vec3 SkyColourHorizon;
uniform vec3 SkyColourZenith;
uniform vec3 SunLightDirection;
uniform vec3 GroundColor;

uniform float SunFocus;
uniform float SunIntensity;
uniform float SunThreshold;
uniform float SkyStrength;

uniform mat4 viewProj;

uniform int NumberOfBounces = 4;    // Ray bounces per sample
uniform int NumberOfRays = 5;       // Mutation iterations per pixel
uniform int DebugMode = 0;          // Debug mode (0: normal, 1: debug view)
uniform int DebugThreshold = 20;
uniform int DebugTest = 0;
uniform int RENDER_MODE = 0;
uniform int LENSSUBPATHS = 6;
uniform int LIGHTSUBPATHS = 6;

uniform int MutationType = 1;       // 0 = small perturbation, 1 = lens perturbation
uniform int NumberOfMutations = 1;       // 0 = small perturbation, 1 = lens perturbation
uniform double uTime;                // Time uniform for animation or randomization

uniform	float DefocusStrength = 5.0f;
uniform	float DivergeStrength = 5.3f;
uniform	float FocusDistance = 2.0f;
uniform int BurnInSamples = 6000;    // Number of paths generated in the burn-in phase
uniform bool BurnInPhase = true;     // Toggle burn-in phase

uniform int METROPLIS_DISPATCH_X;
uniform int METROPLIS_DISPATCH_Y;
const int NUM_DEBUG_STATS = 5;
const float pLargeStep = 0.30;
float pLarge = 0;

shared int localBVHStack[ LOCAL_SIZE_X * LOCAL_SIZE_Y * MAX_STACK_SIZE ];

///////////////////////////////
//    HELPER FUNCTIONS     //
///////////////////////////////

uint wang_hash(inout uint seed)
{
    seed = uint(seed ^ uint(61)) ^ uint(seed >> uint(16));
    seed *= uint(9);
    seed = seed ^ (seed >> 4);
    seed *= uint(0x27d4eb2d);
    seed = seed ^ (seed >> 15);
    return seed;
}
 
float RandomFloat01(inout uint state)
{
    return float(wang_hash(state)) / 4294967296.0;
}

float hash21(vec2 p) {
    p = fract(p * vec2(234.34, 435.345));
    p += dot(p, p + 34.35);
    return fract(sin(dot(p, vec2(12.9898, 78.233))) * 43758.5453);
}

float rand2(inout vec2 state) {
    // Shuffle state
    state = fract(state + 0.1234);
    float r = hash21(state);
    // Optionally do more scrambles to reduce correlation
    return r;
}

// High-quality pseudo-random float generator based on PCG hash
double rand(inout uint state) {
    // PCG hash (permuted congruential generator)
    state = state * 747796405u + 2891336453u;
    uint word = ((state >> ((state >> 28u) + 4u)) ^ state) * 277803737u;
    word = (word >> 22u) ^ word;
    return double(word) / 4294967295.0; // Convert to [0,1) range
}

// Alternative random generator with 2D seed that doesn't modify the seed
float rand2D(vec2 co) {
    // Hash function based on Wang hash and bit manipulation
    uvec2 p = floatBitsToUint(co);
    p.x = 1103515245u * ((p.x >> 1u) ^ p.y);
    p.y = 1103515245u * ((p.y >> 1u) ^ p.x);
    
    uint n = 1103515245u * ((p.x) ^ (p.y >> 3u));
    n = n ^ (n >> 16u);
    return float(n) / 4294967295.0; // Convert to [0,1) range
}

double randHP(inout dvec2 co) {
    // Update seed with high-quality hashing
    co.x += 0.27971;
    co.y += 0.31337;
    const double a = 12.9898;
    const double b = 78.233;
    const double c = 43758.5453;
    
    double dt = dot(co, vec2(a, b));
    double sn = mod(dt, 3.14159);
    
    // Mix previous seed into result for better distribution
    co = fract(co * vec2(2.0371, 7.1571) + vec2(dt, sn));
    return fract(sin(float(dot(co, vec2(a, b)))) * c);
}
// Improved version with 2D seed that updates the seed (for sequence generation)
double rand(inout vec2 co) {
    // Update seed with high-quality hashing
    co.x += 0.27971;
    co.y += 0.31337;
    const float a = 12.9898;
    const float b = 78.233;
    const float c = 43758.5453;
    
    float dt = dot(co, vec2(a, b));
    float sn = mod(dt, 3.14159);
    
    // Mix previous seed into result for better distribution
    co = fract(co * vec2(2.0371, 7.1571) + vec2(dt, sn));
    return fract(sin(dot(co, vec2(a, b))) * c);
}




vec3 CosineSampleHemisphere(vec3 normal, inout vec2 co)
{
   // Use floats instead of doubles for better GPU performance
    float r1 = float(rand(co));
    float r2 = float(rand(co));
    
    // Compute cosine-weighted sample in local space
    float phi = 2.0 * M_PI * r1;
    float r_sqrt = sqrt(r2);
    float x = r_sqrt * cos(phi);
    float y = r_sqrt * sin(phi);
    float z = sqrt(1.0 - r2);  // sqrt(1 - x²-y²) = sqrt(1-r²)
    
    // Create an orthonormal basis (tangent, bitangent, normal)
    vec3 helper = abs(normal.x) > 0.99 ? vec3(0, 1, 0) : vec3(1, 0, 0);
    vec3 tangent = normalize(cross(helper, normal));
    vec3 bitangent = cross(normal, tangent);
    
    // Transform sampled direction to world space
    return tangent * x + bitangent * y + normal * z;
}

// Generate a normally distributed random value.
double randNorm(inout vec2 co) {
    double theta = M_PI * 2 * rand(co);
    double rho = sqrt(-2.0 * log(float(rand(co))));
    return rho * cos(float(theta));
}

// Return a random normalized direction vector.
vec3 RandomDirection(inout vec2 state) {
    return normalize(vec3(randNorm(state), randNorm(state), randNorm(state)));
}

vec3 Refract(vec3 incident, vec3 normal, float eta) {
    float cosI = dot(-incident, normal);
    float cos2T = 1.0 - eta * eta * (1.0 - cosI * cosI);
    
    // Total internal reflection case
    if (cos2T < 0.0)
        return reflect(incident, normal);
        
    return eta * incident + (eta * cosI - sqrt(cos2T)) * normal;
}

vec2 RandomPointInCircle(inout vec2 state)
{
	double angle = rand(state) * 2 * M_PI;
	vec2 pointOnCircle = vec2(cos(float(angle)), sin(float(angle)));
	return pointOnCircle * sqrt(float(rand(state)));
}

// Compute ambient light based on ray direction.
vec3 GetAmbientLight(Ray ray) {
    float gradient = pow(smoothstep(0.0, 0.4, ray.direction.y), 0.35);
    vec3 gradientC = mix(SkyColourHorizon, SkyColourZenith, gradient);

    float groundToSkyT = smoothstep(-0.01, 0.0, ray.direction.y);

    float sun = pow(max(0.0, dot(ray.direction, -SunLightDirection) - SunThreshold), SunFocus) * SunIntensity;
    float sunMask = groundToSkyT >= 1.0 ? 1.0 : 0.0;
    return mix(GroundColor, gradientC, groundToSkyT) + sun * sunMask;
}

// Wrap a float x into a periodic range [minVal, maxVal].
double wrapRange(double x, double minVal, double maxVal) {
    double range = maxVal - minVal;
    x = x - minVal;
    x = mod(x, range);
    if (x < 0.0)
        x += range;
    return x + minVal;
}

// Wrap a vec2 UV coordinate so that:
// uv.x ∈ [-aspect, aspect] and uv.y ∈ [-1, 1].
vec2 wrapUV(dvec2 uv, double aspect) {
    double wrappedX = wrapRange(uv.x, -aspect, aspect);
    double wrappedY = wrapRange(uv.y, -1.0, 1.0);
    return vec2(wrappedX, wrappedY);
}

// Mutate a UV coordinate using an exponential radial distribution.
MutationResults lensPerturbation(dvec2 uv, double aspect, double minPerturb, double maxPerturb, inout dvec2 state) {
    MutationResults results;

    if(randHP(state) < pLargeStep){ 
        ivec2 localThread = ivec2(gl_LocalInvocationID.xy);
        ivec2 workGroup = ivec2(gl_WorkGroupID.xy);

        // Calculate the size of each image region based on the workgroup and dispatch sizes.
        double imageRegionSizeX = 1.0 / double(LOCAL_SIZE_X * METROPLIS_DISPATCH_X);
        double imageRegionSizeY = 1.0 / double(LOCAL_SIZE_Y * METROPLIS_DISPATCH_Y);

        // Calculate the offset of the current thread's image region.
        double imageRegionOffsetX = localThread.x * imageRegionSizeX + workGroup.x * imageRegionSizeX * LOCAL_SIZE_X;
        double imageRegionOffsetY = localThread.y * imageRegionSizeY + workGroup.y * imageRegionSizeY * LOCAL_SIZE_Y;

        double x = randHP(state) * imageRegionSizeX + imageRegionOffsetX;
        double y = randHP(state) * imageRegionSizeY + imageRegionOffsetY;

        dvec2 randomSample = dvec2(x,y);

        double u_random = randomSample.x * 2.0 - 1.0;
        double v_random = randomSample.y * 2.0 - 1.0;
        u_random *= aspect;

        results.large = 1;
        results.uv = wrapUV(vec2(u_random, v_random), aspect);

        return results;
    }
    double U_random = randHP(state);
    double R = maxPerturb * exp(float(-log(float(maxPerturb / minPerturb)) * U_random));
    double phi = (M_PI * 2.0) * randHP(state);
    dvec2 offset = dvec2(R * cos(float(phi)), R * sin(float(phi)));
    dvec2 mutatedUV = uv + offset;

    results.large = 0;
    results.uv = wrapUV(mutatedUV, aspect);
    return results;
}

bool RayIntersectsAABB(Ray ray, vec3 minBounds, vec3 maxBounds, out float tmin, out float tmax) {
    tmin = 0.0;
    tmax = 1000000.0;
    for (int i = 0; i < 3; i++) {
        if (abs(ray.direction[i]) > 1e-6) {
            float t1 = (minBounds[i] - ray.origin[i]) / ray.direction[i];
            float t2 = (maxBounds[i] - ray.origin[i]) / ray.direction[i];
            if (t1 > t2) {
                float tmp = t1;
                t1 = t2;
                t2 = tmp;
            }
            tmin = max(tmin, t1);
            tmax = min(tmax, t2);
            if (tmin > tmax) {
                tmin = 1e21;
                return false;
            }
        } else {
            if (ray.origin[i] < minBounds[i] || ray.origin[i] > maxBounds[i]) {
                tmin = 1e21;
                return false;
            }
        }
    }
    return true;
}

bool RayIntersectsAABB(Ray ray, vec3 minBounds, vec3 maxBounds) {
    float d1, d2;
    return RayIntersectsAABB(ray, minBounds, maxBounds, d1, d2);
}

///////////////////////////////
//  RAY–OBJECT INTERSECTION  //
//       FUNCTIONS           //
///////////////////////////////

HitInfo RayBox(Ray ray, vec3 minBounds, vec3 maxBounds, Material material) {
    HitInfo hitInfo;
    hitInfo.didHit = false;
    float tmin = -1000000.0;
    float tmax = 1000000.0;
    for (int i = 0; i < 3; i++) {
        if (abs(ray.direction[i]) > 1e-6) {
            float t1 = (minBounds[i] - ray.origin[i]) / ray.direction[i];
            float t2 = (maxBounds[i] - ray.origin[i]) / ray.direction[i];
            if (t1 > t2) {
                float tmp = t1;
                t1 = t2;
                t2 = tmp;
            }
            tmin = max(tmin, t1);
            tmax = min(tmax, t2);
            if (tmin > tmax)
                return hitInfo;
        } else if (ray.origin[i] < minBounds[i] || ray.origin[i] > maxBounds[i]) {
            return hitInfo;
        }
    }
    if (tmin < 0.0)
        tmin = tmax;
    if (tmin < 0.0)
        return hitInfo;

    hitInfo.didHit = true;
    hitInfo.dst = tmin;
    hitInfo.hitPoint = ray.origin + ray.direction * tmin;
    hitInfo.material = material;
    vec3 center = (minBounds + maxBounds) * 0.5;
    vec3 relativeHit = hitInfo.hitPoint - center;
    vec3 faceNormals[6] = vec3[6](
        vec3(1, 0, 0), vec3(-1, 0, 0),
        vec3(0, 1, 0), vec3(0, -1, 0),
        vec3(0, 0, 1), vec3(0, 0, -1)
    );
    float maxComponent = -1.0;
    for (int i = 0; i < 6; i++) {
        float d = abs(dot(relativeHit, faceNormals[i]));
        if (d > maxComponent) {
            maxComponent = d;
            hitInfo.normal = faceNormals[i];
        }
    }
    if (dot(hitInfo.normal, ray.direction) > 0.0)
        hitInfo.normal = -hitInfo.normal;
    return hitInfo;
}

HitInfo RaySphere(Ray ray, vec3 sphereCenter, float sphereRadius, Material material) {
    HitInfo hitInfo;
    hitInfo.didHit = false;
    hitInfo.albedo = vec3(1.0);
    hitInfo.type = 0;

    vec3 o_c = ray.origin - sphereCenter;
    float b = dot(ray.direction, o_c);
    float c = dot(o_c, o_c) - sphereRadius * sphereRadius;
    float intersectionState = b * b - c;
    if (intersectionState >= 0.0) {
        float t1 = (-b - sqrt(intersectionState));
        float t2 = (-b + sqrt(intersectionState));
        float dst = (t1 >= 0.0) ? t1 : t2;
        if (dst >= 0.0) {
            hitInfo.didHit = true;
            hitInfo.dst = dst;
            hitInfo.hitPoint = ray.origin + ray.direction * dst;
            hitInfo.normal = normalize(hitInfo.hitPoint - sphereCenter);
            hitInfo.material = material;
        }
    }
    return hitInfo;
}
HitInfo RayTriangle(Ray ray, Triangle tri, Material material, float HasNorm) {
    HitInfo hitInfo;
    hitInfo.didHit = false;
    hitInfo.albedo = vec3(1.0);
    // Compute the two edge vectors of the triangle.
    vec3 edge1 = tri.posB - tri.posA;
    vec3 edge2 = tri.posC - tri.posA;
    
    // Begin calculating determinant - also used to calculate u parameter.
    vec3 pvec = cross(ray.direction, edge2);
    float det = dot(edge1, pvec);
    
    // If the determinant is near zero, the ray lies in the plane of the triangle.
    if (abs(det) < 1e-6)
        return hitInfo;
    
    float invDet = 1.0 / det;
    
    // Calculate distance from vert0 to ray origin.
    vec3 tvec = ray.origin - tri.posA;
    
    // Calculate u parameter and test bounds.
    float u = dot(tvec, pvec) * invDet;
    if (u < 0.0 || u > 1.0)
        return hitInfo;
    
    // Prepare to test v parameter.
    vec3 qvec = cross(tvec, edge1);
    
    // Calculate v parameter and test bounds.
    float v = dot(ray.direction, qvec) * invDet;
    if (v < 0.0 || u + v > 1.0)
        return hitInfo;
    
    // Calculate t, the distance along the ray.
    float t = dot(edge2, qvec) * invDet;
    if (t < 1e-6)
        return hitInfo; // Intersection is too close or behind the ray.
    
    // Valid intersection found.
    hitInfo.didHit = true;
    hitInfo.dst = t;
    hitInfo.hitPoint = ray.origin + ray.direction * t;
    
    // Calculate barycentric coordinate w
    float w = 1.0 - u - v;
    
    // Interpolate vertex normals using barycentric coordinates

    vec3 normal = HasNorm == 0.0 ? 
    normalize(cross(edge1, edge2)) : 
    normalize(w * tri.normA + u * tri.normB + v * tri.normC);

    // Compute the face normal.

    // For double-sided shading: flip the normal if it's facing the ray.
    if (dot(normal, ray.direction) > 0.0)
        normal = -normal;
    
    hitInfo.normal = normal;
    hitInfo.material = material;
    vec2 hitUV = w * tri.uvA + u * tri.uvB + v * tri.uvC;
    hitInfo.albedo = vec3(float(HasNorm + 1), float(HasNorm + 1), float(HasNorm + 1));
    if (material.textureSlot == -1) return hitInfo;
    hitInfo.albedo = texture(diffuseTextures, vec3(hitUV, material.textureSlot)).rgb;

    return hitInfo;
}
///////////////////////////////
//   BVH Traversal Function  //
///////////////////////////////
HitInfo TraverseBVH(Ray ray, int nodeOffset, Material material, float HasNorm, inout int tests[NUM_DEBUG_STATS]) {
    HitInfo closestHit;
    closestHit.didHit = false;
    closestHit.dst   = 1e20;

    // Early out if the root box isn't hit:
    if (!RayIntersectsAABB(ray, nodes[nodeOffset].minBounds, nodes[nodeOffset].maxBounds))
        return closestHit;

    // Build a per-thread flat index into our shared stack:
    int localThreadID = int(gl_LocalInvocationID.x + gl_LocalInvocationID.y * LOCAL_SIZE_X);
    int stackPtr      = 0;

    // Push the root onto shared memory:
    localBVHStack[localThreadID * MAX_STACK_SIZE + stackPtr++] = nodeOffset;

    while (stackPtr > 0) {
        // Pop:
        int nodeIndex = localBVHStack[localThreadID * MAX_STACK_SIZE + --stackPtr];
        BVHNode node  = nodes[nodeIndex];

        if (node.childIndex == 0) {
            // leaf → test triangles
            for (int i = 0; i < node.triangleCount; ++i) {
                Triangle tri = Triangles[node.triangleStartIndex + i];
                tests[1]++;
                HitInfo hit = RayTriangle(ray, tri, material, HasNorm);
                if (hit.didHit && hit.dst < closestHit.dst)
                    closestHit = hit;
            }
        } else {
            // internal → AABB test both children, push the nearer first
            tests[0]++;
            int  a = node.childIndex;
            int  b = node.childIndex + 1;
            float dA, dB, dummy;
            bool hitA = RayIntersectsAABB(ray, nodes[a].minBounds, nodes[a].maxBounds, dA, dummy);
            bool hitB = RayIntersectsAABB(ray, nodes[b].minBounds, nodes[b].maxBounds, dB, dummy);

            // sort so we push farther one first
            int nearChild = (dA <= dB) ? a : b;
            int farChild  = (dA <= dB) ? b : a;
            float dNear   = min(dA, dB);
            float dFar    = max(dA, dB);

            if (dFar  < closestHit.dst && stackPtr < MAX_STACK_SIZE)
                localBVHStack[localThreadID * MAX_STACK_SIZE + stackPtr++] = farChild;
            if (dNear < closestHit.dst && stackPtr < MAX_STACK_SIZE)
                localBVHStack[localThreadID * MAX_STACK_SIZE + stackPtr++] = nearChild;
        }
    }

    return closestHit;
}


///////////////////////////////
//    Debug Ray Function     //
///////////////////////////////
bool DebugRay(vec3 rayOrigin, vec3 rayDir, vec3 start, vec3 end, out float debugT) {
    // Compute the vector along the debug line segment.
    vec3 ab = end - start;
    // Compute the vector from the start of the segment to the ray origin.
    vec3 ao = rayOrigin - start;
    // Cross products for calculating the closest distance from the ray to the segment.
    vec3 ab_cross_d = cross(ab, rayDir);
    vec3 ao_cross_d = cross(ao, rayDir);
    // Compute squared length of the segment.
    float ab_dot_ab = dot(ab, ab);
    // Project the vector from start to ray origin onto the segment.
    float ab_dot_ao = dot(ab, ao);
    // Compute dot product of the segment with the ray direction.
    float ab_dot_d = dot(ab, rayDir);
    // Calculate the parameter 't' along the ray at which the closest approach occurs.
    float t = (ab_dot_ao * ab_dot_d - ab_dot_ab * dot(ao, rayDir)) /
              (ab_dot_ab * dot(rayDir, rayDir) - ab_dot_d * ab_dot_d);
    // Compute the closest point on the ray.
    vec3 closestPoint = rayOrigin + rayDir * t;
    // Project the closest point onto the line segment.
    vec3 projOnSegment = start + ab * clamp(dot(closestPoint - start, ab) / ab_dot_ab, 0.0, 1.0);
    // Compute the distance from the closest point to the segment.
    float dist = length(closestPoint - projOnSegment);
    // Output the parameter 't' for debugging purposes.
    debugT = t;
    // Return true if the distance is less than the defined threshold.
    return dist < 0.01; // Line thickness threshold
}
/*
HitInfo RayAllBoxes(Ray ray) {
    HitInfo closestHit;
    closestHit.didHit = false;
    closestHit.dst = 1.0 / 0.0; // Infinity
    closestHit.hitPoint = vec3(0.0);
    closestHit.normal = vec3(0.0);
    for (int i = 0; i < NumBoxes; i++) {
        DebugBox box = DebugBoxes[i];
        vec3 minBounds = box.position - box.size * 0.5;
        vec3 maxBounds = box.position + box.size * 0.5;
        HitInfo hitInfo = RayBox(ray, minBounds, maxBounds, box.material);
        if (hitInfo.didHit && hitInfo.dst < closestHit.dst)
            closestHit = hitInfo;
    }
    return closestHit;

}
*/
HitInfo RayAllSpheres(Ray ray) {
    HitInfo closestHit;
    closestHit.didHit = false;
    closestHit.hitPoint = vec3(0.0);
    closestHit.normal = vec3(0.0);
    closestHit.dst = 1.0 / 0.0; // Infinity
    const float epsilon = 1e-5; // threshold to avoid z-fighting

    for (int i = 0; i < NumSpheres; i++) {
        Sphere sphere = spheres[i];
        HitInfo hitInfo = RaySphere(ray, sphere.position, sphere.radius.x, sphere.material);
        if (hitInfo.didHit && hitInfo.dst < closestHit.dst && hitInfo.dst > epsilon)
        {
            hitInfo.objIndex = i;
            closestHit = hitInfo;
        }
    }
    return closestHit;
}

HitInfo RayAllBVHMeshes(Ray ray, inout int tests[NUM_DEBUG_STATS]) {
    HitInfo closestHit;
    closestHit.didHit = false;
    closestHit.hitPoint = vec3(0.0);
    closestHit.normal = vec3(0.0);
    closestHit.dst = 1.0 / 0.0; // Infinity


    for (int i = 0; i < NumModels; i++) {
        Model model = Models[i];
        HitInfo info = TraverseBVH(ray, model.NodeOffset, model.material, model.HasNorm, tests);
        if (info.didHit && info.dst < closestHit.dst)
        {
            info.objIndex = i;
            info.type = 1;
            closestHit = info;
        }
    }
    return closestHit;
}

///////////////////////////////
//    RAY TRACING FUNCTIONS  //
///////////////////////////////

float SchlickApproximation(float cosine, float refractiveIndex) {
    float r0 = (1.0 - refractiveIndex) / (1.0 + refractiveIndex);
    r0 = r0 * r0;
    return r0 + (1.0 - r0) * pow(1.0 - cosine, 5.0);
}

vec3 FullTrace(Ray ray, inout vec2 state) {
    vec3 rayColor = vec3(1.0);
    vec3 rayLight = vec3(0.0);
    int tests[NUM_DEBUG_STATS];

    for (int i = 0; i < NUM_DEBUG_STATS; i++)
        tests[i] = 0;

    // Optional debug: if the ray is near a debug line, return red.
    vec3 debugStart = vec3(-1.0, 1.0, -3.0);
    vec3 debugEnd = vec3(1.0, 1.0, -3.0);
    float debugT;
    //if (DebugRay(ray.origin, ray.direction, debugStart, debugEnd, debugT))
    //    return vec3(1.0, 0.0, 0.0); // Red debug line

    for (int i = 0; i < NumberOfBounces; i++) {
        HitInfo hitInfo;
        hitInfo.didHit = false;
        hitInfo.dst = 1e20;  // Initialize with "infinity"

        // Test spheres first since they're typically faster
        HitInfo hitInfoSphere = RayAllSpheres(ray);
        if (hitInfoSphere.didHit) {
            hitInfo = hitInfoSphere;
        }

        // Only test BVH if we need to (spheres didn't hit or hit something far away)
        if (!hitInfo.didHit || hitInfo.dst > 1) {
            HitInfo hitInfoMesh = RayAllBVHMeshes(ray, tests);
            if (hitInfoMesh.didHit && hitInfoMesh.dst < hitInfo.dst) {
                hitInfo = hitInfoMesh;
            }
        }

        if (hitInfo.didHit) {
            vec3 emission = hitInfo.material.emmisionColor * hitInfo.material.emmisionStrength.x;
            rayLight += emission * rayColor;
            vec3 normal = hitInfo.normal;


            // Handle translucent materials
            if (hitInfo.material.isTranslucent == 1) {
                // Determine if ray is entering or exiting the medium
                bool entering = dot(ray.direction, normal) < 0.0;
                vec3 surfaceNormal = entering ? normal : -normal;
                
                // Adjust refractive indices based on whether we're entering or exiting
                float n1 = entering ? 1.0 : hitInfo.material.refractiveIndex;
                float n2 = entering ? hitInfo.material.refractiveIndex : 1.0;
                float eta = n1 / n2;
                
                // Calculate Fresnel reflection coefficient using Schlick's approximation
                float cosTheta = abs(dot(-ray.direction, surfaceNormal));
                float reflectionCoeff = SchlickApproximation(cosTheta, eta);
                
                // Probabilistic reflection/refraction based on Fresnel
                if (rand(state) < reflectionCoeff) {
                    // Reflect
                    ray.direction = reflect(ray.direction, surfaceNormal);
                    rayColor *= hitInfo.material.specularColor;
                } else {
                    // Refract
                    ray.direction = Refract(ray.direction, surfaceNormal, eta);
                    // Apply absorption based on distance traveled through medium
                    if (entering) {
                        // No absorption when entering, apply color when exiting
                        rayColor *= hitInfo.material.diffuseColor;
                    } else {
                        // Optional: Apply Beer's law for absorption when exiting
                        // float distanceThroughMedium = hitInfo.dst;
                        // vec3 absorption = exp(-hitInfo.material.absorptionCoefficient * distanceThroughMedium);
                        // rayColor *= absorption;
                    }
                }
            } else {
                // Your existing opaque material handling
                vec3 diffuseDir = normalize(CosineSampleHemisphere(normal, state));
                vec3 specularDir = reflect(ray.direction, normal);
                bool isSpecular = hitInfo.material.specularProbability.x >= rand(state);
                ray.direction = mix(diffuseDir, specularDir, hitInfo.material.smoothness.x * float(isSpecular));
                vec3 effectiveDiffuse = hitInfo.material.diffuseColor * hitInfo.albedo;
                rayColor *= mix(effectiveDiffuse, hitInfo.material.specularColor, float(isSpecular));
            }

            // Random early exit if ray colour is nearly 0
            float p = max(rayColor.r, max(rayColor.g, rayColor.b));
            if (rand(state) >= p) {
                break;
            }
            ray.origin = hitInfo.hitPoint + ray.direction * 1e-4;
            rayColor /= p;
        } else {
            // No hit: accumulate ambient sky light and break
            rayLight += rayColor * GetAmbientLight(ray) * SkyStrength;
            break;
        }
    }

    vec3 color;
    float debugThreshold = DebugThreshold;
    vec3 debugOverflowColor = vec3(1, 1, 0);
    switch (DebugMode) {
        case 0:
            color = rayLight; // Actual color
            break;
        case 1:
            color = (tests[DebugTest] < debugThreshold) ?
                        vec3(tests[DebugTest] / float(debugThreshold)) :
                        debugOverflowColor; // Green debug
            break;
        default:
            color = rayLight; // Fallback color
            break;
    }
    return color;
}

#define RENDER_MODE_3 // NEXT EVENT ESTIMATION (NEE)


////////////////////////////////////////////////////////////////////////////////
//                                                                            //
//  ╔════════════════════════════════════════════════════════════════════╗    //
//  ║                                                                    ║    //
//  ║                        BIDIRECTIONAL SAMPLING                      ║    //
//  ║                                                                    ║    //
//  ╚════════════════════════════════════════════════════════════════════╝    //
//                                                                            //
//  Implements bidirectional sampling for advanced global illumination.       //
//                                                                            //
////////////////////////////////////////////////////////////////////////////////


// Define a maximum path length (number of vertices)
#define MAX_PATH_LENGTH 6

// Structure to store a vertex along a path.
struct Vertex {
    vec3 position;
    int objIndex;
    vec3 normal;
    int objType;
    vec3 throughput; // Cumulative product of BSDF, cosine, etc.
    float PDF;
    vec3 emission;
};


// Structure to store an emissive object (could be a sphere or triangle)
struct EmissiveObject {
    vec3 position;      // Center position (for sphere) or barycenter (for triangle)
    float radius;       // Radius for sphere, or area for triangle
    vec3 normal;        // Normal direction (for triangles, unused for spheres)
    float type;         // 0 = sphere, 1 = triangle
    int objectIndex;    // Index into original array (spheres or triangles)
    float power;        // Total emissive power (used for importance sampling)
    vec3 emission;      // Emission color
    float padding;      // For alignment
};

// Structure to store the result of a path trace (end vertex and throughput)
struct PathResult {
    vec3 position;     // Final vertex position
    int objIndex;      // Object index of the final hit
    vec3 normal;       // Surface normal at final vertex
    int objType;       // Object type of the final hit
    vec3 throughput;   // Accumulated path throughput
    bool isEmissive;   // Whether the final vertex is emissive
    vec3 emission;     // Emission at the final vertex (if emissive)
};

layout(std430, binding = 21) buffer CameraPathBuffer {
    Vertex cameraPathsGlobal[];
};

// Binding 22: Global buffer storing light path vertices for all threads
layout(std430, binding = 22) buffer LightPathBuffer {
    Vertex lightPathsGlobal[];
};

// Binding 23: Buffer containing all emissive objects for efficient light sampling
layout(std430, binding = 23) buffer EmissiveObjectsBuffer {
    EmissiveObject emissiveObjects[];
};

// Binding 24: Total emissive power and object count
layout(std430, binding = 24) buffer EmissivePowerData {
    float totalEmissivePower;
    int numEmissiveObjects;
    vec2 padding;
};

Material GetMaterial(int objIndex, int type){

    if(type == 0) return spheres[objIndex].material;
    else if(type == 1) return Models[objIndex].material;
}

Material GetMaterial(int objIndex, int type, Ray ray) {
    // Handle sky or invalid indices
    if (objIndex < 0 || type < 0) {
        Material skyMat;
        // Initialize with sky values using the provided ray
        skyMat.emmisionColor = GetAmbientLight(ray);
        skyMat.emmisionStrength = SkyStrength;
        skyMat.diffuseColor = vec3(0.0);
        skyMat.specularProbability = 0.0;
        skyMat.smoothness = 0.0;
        skyMat.isTranslucent = 0;
        skyMat.textureSlot = -1;
        skyMat.refractiveIndex = 1.0;
        return skyMat;
    }
    
    if (type == 0) return spheres[objIndex].material;
    else if (type == 1) return Models[objIndex].material;
    
    // Fallback for unknown type
    Material defaultMat;
    // Initialize with neutral values
    defaultMat.emmisionColor = vec3(0.0);
    defaultMat.emmisionStrength = 0.0;
    defaultMat.diffuseColor = vec3(0.5);
    defaultMat.specularProbability = 0.0;
    defaultMat.smoothness = 0.0;
    defaultMat.isTranslucent = 0;
    defaultMat.textureSlot = -1;
    defaultMat.refractiveIndex = 1.0;
    return defaultMat;
}

Material VertexMat(Vertex v){
    return GetMaterial(v.objIndex, v.objType);
}

// Generates a camera path and returns the result
int TraceCameraPath(vec3 rayDirection, int maxBounces, int baseIndex, inout vec2 seed) {
    Ray ray;
    ray.origin = camera.position;
    ray.direction = rayDirection;

    // The initial throughput is unity
    vec3 throughput = vec3(1.0);
    bool hitEmissive = false;
    vec3 emission = vec3(0.0);
    float PDF = 1.0;
  
    // Used for BVH traversal
    int tests[NUM_DEBUG_STATS];
    for (int j = 0; j < NUM_DEBUG_STATS; j++) { 
        tests[j] = 0; 
    }

    // Maximum bounces to simulate
    cameraPathsGlobal[baseIndex].position = camera.position;
    cameraPathsGlobal[baseIndex].throughput = throughput;
    cameraPathsGlobal[baseIndex].PDF = PDF;
    cameraPathsGlobal[baseIndex].emission = emission;

    int count = 0;
    count++;

    // Trace the path
    for (int bounce = 0; bounce < maxBounces; bounce++) {

        int vertexIndex = baseIndex + count;

        HitInfo hitInfo;
        hitInfo.didHit = false;
        hitInfo.dst = 1e20;  // Initialize with "infinity"

        // Test spheres first since they're typically faster
        HitInfo hitInfoSphere = RayAllSpheres(ray);
        if (hitInfoSphere.didHit) {
            hitInfo = hitInfoSphere;
        }

        // Only test BVH if we need to (spheres didn't hit or hit something far away)
        if (!hitInfo.didHit || hitInfo.dst > 1) {
            HitInfo hitInfoMesh = RayAllBVHMeshes(ray, tests);
            if (hitInfoMesh.didHit && hitInfoMesh.dst < hitInfo.dst) {
                hitInfo = hitInfoMesh;
            }
        }
        
        // If no intersection, simulate sky hit
        if (!hitInfo.didHit) {

            cameraPathsGlobal[vertexIndex].position = ray.origin + ray.direction * 100000.0;
            cameraPathsGlobal[vertexIndex].normal = -ray.direction; // Use incoming direction as normal
            
            cameraPathsGlobal[vertexIndex].throughput = throughput;
            cameraPathsGlobal[vertexIndex].PDF = PDF;
            cameraPathsGlobal[vertexIndex].objType = -1;
            cameraPathsGlobal[vertexIndex].objIndex = -1;
            cameraPathsGlobal[vertexIndex].emission = emission + GetAmbientLight(ray) * SkyStrength * throughput;

            count++;

            return count;
        }

        // Handle different material types and scattering events
        vec3 newDir;
        bool isSpecular = false;
        
        
  
        // Check if we've reached an emissive surface
        if (hitInfo.material.emmisionStrength.x > 0) {
            emission += hitInfo.material.emmisionColor * hitInfo.material.emmisionStrength * throughput;
            //return count;
        }

        // Handle translucent materials with refraction
        if (hitInfo.material.isTranslucent == 1) {
            // Determine if ray is entering or exiting the medium
            bool entering = dot(ray.direction, hitInfo.normal) < 0.0;
            vec3 surfaceNormal = entering ? hitInfo.normal : -hitInfo.normal;
            
            // Adjust refractive indices
            float n1 = entering ? 1.0 : hitInfo.material.refractiveIndex;
            float n2 = entering ? hitInfo.material.refractiveIndex : 1.0;
            float eta = n1 / n2;
            
            // Calculate Fresnel reflection coefficient
            float cosTheta = abs(dot(-ray.direction, surfaceNormal));
            float reflectionCoeff = SchlickApproximation(cosTheta, eta);
            
            // Probabilistic reflection/refraction
            if (rand(seed) < reflectionCoeff) {
                // Reflect
                newDir = reflect(ray.direction, surfaceNormal);
                isSpecular = true;
                throughput *= hitInfo.material.specularColor;
            } else {
                // Refract
                newDir = Refract(ray.direction, surfaceNormal, eta);
                isSpecular = true;
                
                // Apply absorption based on distance traveled
                if (entering) {
                    throughput *= hitInfo.material.diffuseColor;
                }
            }
        } else {
            // Handle regular opaque materials
            vec3 diffuseDir = CosineSampleHemisphere(hitInfo.normal, seed);
            vec3 specularDir = reflect(ray.direction, hitInfo.normal);
            isSpecular = hitInfo.material.specularProbability.x >= rand(seed);
            
            newDir = mix(diffuseDir, specularDir, hitInfo.material.smoothness.x * float(isSpecular));
            
            // Update throughput based on the BRDF
            vec3 effectiveDiffuse = hitInfo.material.diffuseColor * hitInfo.albedo;
            throughput *= mix(effectiveDiffuse, hitInfo.material.specularColor, float(isSpecular)) 
                        * max(0.0, dot(newDir, hitInfo.normal));
        }
        

        // Russian roulette for path termination
        float p = max(throughput.r, max(throughput.g, throughput.b));
        if (bounce > 2 && rand(seed) >= p) {
            // Path terminated by Russian roulette
            cameraPathsGlobal[vertexIndex].position = hitInfo.hitPoint;
            cameraPathsGlobal[vertexIndex].normal = hitInfo.normal;
            cameraPathsGlobal[vertexIndex].throughput = throughput;
            cameraPathsGlobal[vertexIndex].PDF = PDF;
            cameraPathsGlobal[vertexIndex].objIndex = hitInfo.objIndex;
            cameraPathsGlobal[vertexIndex].objType = hitInfo.type;
            cameraPathsGlobal[vertexIndex].emission = emission;
            count++;

            return count;
        }

        if (bounce > 2 && p > 0.0) {
            throughput /= p; // Compensate for termination probability
        }

        cameraPathsGlobal[vertexIndex].position = hitInfo.hitPoint;
        cameraPathsGlobal[vertexIndex].normal = hitInfo.normal;
        cameraPathsGlobal[vertexIndex].throughput = throughput;
        cameraPathsGlobal[vertexIndex].PDF = PDF;
        cameraPathsGlobal[vertexIndex].objIndex = hitInfo.objIndex;
        cameraPathsGlobal[vertexIndex].objType = hitInfo.type;
        cameraPathsGlobal[vertexIndex].emission = emission;


        count++;
        // Spawn the next ray
        ray.origin = hitInfo.hitPoint + newDir * 1e-4;
        ray.direction = newDir;


    }
    
    // Return the final vertex
    return count;
}

// Generates a light path and returns the result
int TraceLightPath(inout vec2 seed, int maxBounces, int baseIndex) {
    PathResult result;
    int count = 0;
    
    // Initialize with invalid result
    result.throughput = vec3(0.0);
    result.isEmissive = false;
    
    // First determine whether to sample from sky/environment or scene light
    bool sampleSky = (SkyStrength > 0.01) && (rand(seed) < 0.3);
    
    if (sampleSky) {
        // Sample a direction for the sky
        double u = rand(seed);
        double v = rand(seed);
        double theta = 2.0 * M_PI * u;
        double phi = acos(float(2.0 * v - 1.0)); // Sample full sphere
        
        // Convert to Cartesian coordinates
        vec3 skyDir = vec3(
            sin(float(phi)) * cos(float(theta)),
            cos(float(phi)),
            sin(float(phi)) * sin(float(theta))
        );
        
        // Create a virtual sky vertex far away
        result.position = camera.position + skyDir * 100000.0;
        result.normal = -skyDir;
        
        // Setup sky material and emission
        Ray skyRay;
        skyRay.origin = camera.position;
        skyRay.direction = skyDir;
        
        result.throughput = GetAmbientLight(skyRay) * SkyStrength;
        result.objIndex = -1;
        result.objType = -1;
        result.isEmissive = true;
        result.emission = result.throughput;
         // Store the sky vertex
        lightPathsGlobal[baseIndex].position = camera.position + skyDir * 100000.0;
        lightPathsGlobal[baseIndex].normal = -skyDir;
        lightPathsGlobal[baseIndex].throughput =  GetAmbientLight(skyRay) * SkyStrength;
        lightPathsGlobal[baseIndex].PDF = 1.0 / (4.0 * M_PI); // Uniform sampling over sphere
        lightPathsGlobal[baseIndex].objType = -1;
        lightPathsGlobal[baseIndex].objIndex = -1;   
        lightPathsGlobal[baseIndex].emission = result.throughput;   
    
        return count;
    }
    
    // Check if we have any emissive objects
    if (numEmissiveObjects == 0) {
        return count; // Invalid result - no light sources
    }
    
    // Sample an emissive object based on relative power
    double r = rand(seed) * totalEmissivePower;
    float cumulative = 0.0;
    int selectedIndex = 0;
    
    // Find the selected emissive object
    for (int i = 0; i < numEmissiveObjects; i++) {
        cumulative += emissiveObjects[i].power;
        if (r <= cumulative) {
            selectedIndex = i;
            break;
        }
    }
    
    EmissiveObject lightObj = emissiveObjects[selectedIndex];
    float lightSelectionPDF = lightObj.power / totalEmissivePower;
     
    // Sample a point on the emissive object
    vec3 lightPos;
    vec3 normal;
    float areaPDF;
    
    if (lightObj.type < 0.5) {
        // This is a sphere light
        double u = rand(seed);
        double v = rand(seed);
        double theta = 2.0 * M_PI * u;
        float phi = acos(float(1.0 - 2.0 * v));
        float r = lightObj.radius;
        
        // Point on sphere
        lightPos = lightObj.position + vec3(
            r * sin(float(phi)) * cos(float(theta)),
            r * sin(float(phi)) * sin(float(theta)),
            r * cos(float(phi))
        );
        
        // Surface normal at the sampled point
        normal = normalize(lightPos - lightObj.position);
        
        // PDF = 1 / (surface area of sphere)
        areaPDF = 1.0 / (4.0 * M_PI * r * r);
    }
    else {
        // This is a triangle light
        Triangle tri = Triangles[lightObj.objectIndex];
        
        // Sample a point on triangle using barycentric coordinates
        double u = rand(seed);
        double v = rand(seed);
        if (u + v > 1.0) {
            u = 1.0 - u;
            v = 1.0 - v;
        }
        double w = 1.0 - u - v;
        
        // Compute position on triangle
        lightPos = vec3(u * tri.posA + v * tri.posB + w * tri.posC);
        
        // Compute normal
        if (lightObj.normal.x != 0.0 || lightObj.normal.y != 0.0 || lightObj.normal.z != 0.0) {
            normal = lightObj.normal;
        } 
        else {
            vec3 edge1 = tri.posB - tri.posA;
            vec3 edge2 = tri.posC - tri.posA;
            normal = normalize(cross(edge1, edge2));
        }
        
        // PDF = 1 / (area of triangle)
        areaPDF = 1.0 / lightObj.radius; // We stored area in the radius field
    }
    
    // Set initial light vertex
    result.position = lightPos;
    result.normal = normal;
    result.throughput = lightObj.emission;
    result.objIndex = lightObj.objectIndex;
    result.objType = int(lightObj.type);
    result.isEmissive = true;
    result.emission = lightObj.emission;
    
    // Initialize the first vertex (light source)
    lightPathsGlobal[baseIndex].position = lightPos;
    lightPathsGlobal[baseIndex].normal = normal;
    

    lightPathsGlobal[baseIndex].throughput = lightObj.emission;
    lightPathsGlobal[baseIndex].PDF = areaPDF * lightSelectionPDF;
    lightPathsGlobal[baseIndex].objIndex = lightObj.objectIndex;
    lightPathsGlobal[baseIndex].objType = int(lightObj.type);
    lightPathsGlobal[baseIndex].emission = lightObj.emission;


    // Initial direction from light
    vec3 rayDir = CosineSampleHemisphere(normal, seed);
    
    Ray ray;
    ray.origin = lightPos + rayDir * 1e-4;
    ray.direction = rayDir;
    
    // Adjust throughput for first bounce
    vec3 throughput = result.throughput / M_PI;
    // Maximum bounces to simulate
    
    int tests[NUM_DEBUG_STATS];
    for (int j = 0; j < NUM_DEBUG_STATS; j++) { 
        tests[j] = 0; 
    }

    // Trace the light path
    for (int bounce = 0; bounce < maxBounces; bounce++) {

        int vertexIndex = baseIndex + count;

        HitInfo hitInfo;
        hitInfo.didHit = false;
        hitInfo.dst = 1e20;  // Initialize with "infinity"

        // Test spheres first since they're typically faster
        HitInfo hitInfoSphere = RayAllSpheres(ray);
        if (hitInfoSphere.didHit) {
            hitInfo = hitInfoSphere;
        }

        // Only test BVH if we need to (spheres didn't hit or hit something far away)
        if (!hitInfo.didHit || hitInfo.dst > 1) {
            HitInfo hitInfoMesh = RayAllBVHMeshes(ray, tests);
            if (hitInfoMesh.didHit && hitInfoMesh.dst < hitInfo.dst) {
                hitInfo = hitInfoMesh;
            }
        }
        
        if (!hitInfo.didHit) {
            // No hit - path terminates
            //result.throughput = vec3(0.0); // Mark as invalid
            return count;
        }    

        if (hitInfo.material.emmisionStrength.x > 0.0) {
            result.isEmissive = true;
            result.emission += hitInfo.material.emmisionColor * hitInfo.material.emmisionStrength * throughput;
            lightPathsGlobal[vertexIndex].emission += hitInfo.material.emmisionColor * hitInfo.material.emmisionStrength * throughput;
        }
        
        // Handle different material types
        vec3 newDir;
        bool isSpecular = false;
        
        // Handle translucent materials with refraction
        if (hitInfo.material.isTranslucent == 1) {
            // Similar to camera path...
            bool entering = dot(ray.direction, hitInfo.normal) < 0.0;
            vec3 surfaceNormal = entering ? hitInfo.normal : -hitInfo.normal;
            
            float n1 = entering ? 1.0 : hitInfo.material.refractiveIndex;
            float n2 = entering ? hitInfo.material.refractiveIndex : 1.0;
            float eta = n1 / n2;
            
            float cosTheta = abs(dot(-ray.direction, surfaceNormal));
            float reflectionCoeff = SchlickApproximation(cosTheta, eta);
            
            if (rand(seed) < reflectionCoeff) {
                // Reflect
                newDir = reflect(ray.direction, surfaceNormal);
                isSpecular = true;
                throughput *= hitInfo.material.specularColor;
            } else {
                // Refract
                newDir = Refract(ray.direction, surfaceNormal, eta);
                isSpecular = true;
                
                if (entering) {
                    throughput *= hitInfo.material.diffuseColor;
                }
            }
        } else {
            // Handle regular opaque materials
            vec3 diffuseDir = CosineSampleHemisphere(hitInfo.normal, seed);
            vec3 specularDir = reflect(ray.direction, hitInfo.normal);
            isSpecular = hitInfo.material.specularProbability.x >= rand(seed);
            
            newDir = mix(diffuseDir, specularDir, hitInfo.material.smoothness.x * float(isSpecular));
            
            // Update throughput
            vec3 effectiveDiffuse = hitInfo.material.diffuseColor * hitInfo.albedo;
            throughput *= mix(effectiveDiffuse, hitInfo.material.specularColor, float(isSpecular)) / M_PI;
        }
        
        // Russian roulette
        float p = max(throughput.r, max(throughput.g, throughput.b));
        if (bounce > 2 && rand(seed) >= p) {
            // Path terminated by Russian roulette
            result.throughput = vec3(0.0); // Mark as invalid
            return count;
        }

        if (bounce > 2 && p > 0.0) {
            throughput /= p; // Compensate for termination probability
        }
        

        // Set up next ray
        ray.origin = hitInfo.hitPoint + newDir * 1e-4;
        ray.direction = newDir;

        // Store the current vertex
        result.position = hitInfo.hitPoint;
        result.normal = hitInfo.normal;
        result.throughput = throughput;
        result.objIndex = hitInfo.objIndex;
        result.objType = hitInfo.type;
        result.isEmissive = false;

        lightPathsGlobal[vertexIndex].position = hitInfo.hitPoint;
        lightPathsGlobal[vertexIndex].normal = hitInfo.normal;
        lightPathsGlobal[vertexIndex].throughput = throughput;
        lightPathsGlobal[vertexIndex].objIndex = hitInfo.objIndex;
        lightPathsGlobal[vertexIndex].objType = hitInfo.type;

        count++;
    }
    // Return the final vertex
    return count;
}

#define MAX_PATH_TECHNIQUES 20

// Compute MIS weights according to the paper (Section 10.2)
// This uses the balance or power heuristic from Chapter 9

// Calculates the probability ratios needed for MIS weights
float ComputeProbabilityRatio(Vertex vA, Vertex vNext, Vertex vPrev) {
    // Use stored PDFs instead of recalculating
    const float EPSILON = 1e-5;
    const float MAX_RATIO = 1e6;
    
    // Check for specular vertices - cannot be sampled bidirectionally
    Material vMat = VertexMat(vA);
    if (vMat.specularProbability.x > 0.0) {
        return 0.0; // Cannot generate specular vertices from the other direction
    }
    
    // Instead of recalculating all the geometry terms and BSDF probabilities,
    // use the stored PDFs which represent the probability of sampling
    // this path segment from each direction
    float forwardPDF = vA.PDF; // PDF of sampling vNext from vA
    float reversePDF = vPrev.PDF; // PDF of sampling vA from vPrev
    
    // Prevent division by zero
    if (forwardPDF < EPSILON) {
        return MAX_RATIO;
    }
    
    // Calculate ratio with clamping to avoid extremely large values
    float ratio = reversePDF / forwardPDF;
    
    // Clamp to reasonable range
    return clamp(ratio, 0.0, MAX_RATIO);
}
// Balance heuristic from the paper (Chapter 9)
float BalanceHeuristic(float pdfA, float sumPdf) {
    return pdfA / sumPdf;
}

// Power heuristic (beta = 2) from the paper (Chapter 9)
float PowerHeuristic(float pdfA, float sumPdfSquared, float pdfASquared) {
    return pdfASquared / sumPdfSquared;
}

float SimplifiedMISWeight(int s, int t) {
    float weight = 1.0 / float(s + t + 1);
    return weight;
}

// Compute MIS weight for a specific sampling technique
float ComputeMISWeight(float pathProbs[MAX_PATH_TECHNIQUES], int techniqueIndex, int numTechniques, int beta) {
    // Get the probability for this technique
    float pdf = pathProbs[techniqueIndex];
    if (pdf <= 0.0) return 0.0; // Technique cannot generate this path
    
    float sumPdf = 0.0;
    float sumPdfSquared = 0.0;
    float pdfSquared = pdf * pdf;
    
    // Sum PDFs for balance heuristic or squared PDFs for power heuristic
    for (int i = 0; i < numTechniques && i < MAX_PATH_TECHNIQUES; i++) {

        float otherPdf = pathProbs[i];
        if (otherPdf > 0.0) {
            if (beta == 1) {
                // Balance heuristic
                sumPdf += otherPdf;
            } else {
                // Power heuristic with beta=2
                sumPdfSquared += otherPdf * otherPdf;
            }
        }
    }
    
    if (sumPdf <= 0.0 || sumPdfSquared <= 0.0) return 1.0;

    // Calculate weight based on selected heuristic
    if (beta == 1) {
        return BalanceHeuristic(pdf, sumPdf);
    } else {
        return PowerHeuristic(pdf, sumPdfSquared, pdfSquared);
    }
}

uniform int ProgressiveSteps = 9;  // Total number of connection strategies to cycle through
uniform int ProgressiveIndex = 0;  // Current step in the progressive rendering cycle

// Optimized visibility test that returns early on first hit
bool FastVisibilityTest(vec3 start, vec3 end) {
    Ray shadowRay;
    shadowRay.origin = start + normalize(end - start) * 1e-4;
    shadowRay.direction = normalize(end - start);
    float maxDist = length(end - start) - 2e-4;
    
    // Check spheres first (usually fewer objects)
    for (int i = 0; i < NumSpheres; i++) {
        Sphere sphere = spheres[i];
        if (sphere.material.isTranslucent == 0) {
            HitInfo hit = RaySphere(shadowRay, sphere.position, sphere.radius.x, sphere.material);
            if (hit.didHit && hit.dst < maxDist) {
                return false;  // Early return on hit
            }
        }
    }
    
    // Check BVH with early termination
    int tests[NUM_DEBUG_STATS];
    for (int j = 0; j < NUM_DEBUG_STATS; j++) { 
        tests[j] = 0; 
    }
    
    for (int i = 0; i < NumModels; i++) {
        Model model = Models[i];
        if ( model.material.isTranslucent == 0) {
            // Check bounding box first
            if (RayIntersectsAABB(shadowRay, nodes[model.NodeOffset].minBounds, nodes[model.NodeOffset].maxBounds)) {
                // Only do full traversal if bounding box hit
                HitInfo hit = TraverseBVH(shadowRay, model.NodeOffset, model.material, model.HasNorm, tests);
                if (hit.didHit && hit.dst < maxDist) {
                    return false;  // Early return on hit
                }
            }
        }
    }
    
    return true;  // No hits found
}

// Simplified visibility test for sky
bool IsVisibleToSky(vec3 position, vec3 direction) {
    Ray skyRay;
    skyRay.origin = position + direction * 1e-4;
    skyRay.direction = direction;
    
    // We don't need the full distance check for sky visibility
    // Just check if there's any opaque object in the way
    
    // Check spheres first (usually fewer objects)
    for (int i = 0; i < NumSpheres; i++) {
        Sphere sphere = spheres[i];
        if (sphere.material.isTranslucent == 0) {
            HitInfo hit = RaySphere(skyRay, sphere.position, sphere.radius.x, sphere.material);
            if (hit.didHit) {
                return false;  // Early return on hit
            }
        }
    }
    
    // Check BVH with early termination
    int tests[NUM_DEBUG_STATS];
    for (int j = 0; j < NUM_DEBUG_STATS; j++) { 
        tests[j] = 0; 
    }
    
    for (int i = 0; i < NumModels; i++) {
        Model model = Models[i];
        if (model.material.isTranslucent == 0) {
            // Check bounding box first
            if (RayIntersectsAABB(skyRay, nodes[model.NodeOffset].minBounds, nodes[model.NodeOffset].maxBounds)) {
                // Only do full traversal if bounding box hit
                HitInfo hit = TraverseBVH(skyRay, model.NodeOffset, model.material, model.HasNorm, tests);
                if (hit.didHit) {
                    return false;  // Early return on hit
                }
            }
        }
    }
    
    return true;  // No hits found
}

// Calculate all possible path sampling probabilities using the relations from equation 10.9
void CalculatePathProbabilities(int camPathBase, int camCount, int lightPathBase, int lightCount, 
                               inout float pathProbs[MAX_PATH_TECHNIQUES]) {
    // We start with p_s,t = 1.0 (the actual sampling technique used)
    // and compute all other p_i relative to this
    int s = 0; // light vertices
    int t = 0; // eye vertices
    
    // For a path of length k = s + t - 1, there are k + 2 possible sampling techniques
    int k = camCount + lightCount - 2; // The -2 accounts for overlap at connecting vertices
    
    // Initialize all to 0 except the one we used
    for (int i = 0; i < MAX_PATH_TECHNIQUES; i++) {
        pathProbs[i] = 0.0;
    }
    
    // Set the probability for the technique we actually used to 1.0
    int actualTechniqueIndex = s;
    pathProbs[actualTechniqueIndex] = 1.0;
    
    // Calculate ratios for techniques with more light vertices (s+1, s+2, ...)
    float currentRatio = 1.0;
    for (int i = s + 1; i <= k + 1 && i < MAX_PATH_TECHNIQUES; i++) {
        // Get the vertices involved in this transition
        Vertex vCam = cameraPathsGlobal[camPathBase + camCount - 1 - (i - s)];
        Vertex vPrev = (i - s - 1 >= 0) ? lightPathsGlobal[lightPathBase + i - s - 1] : vCam;
        Vertex vNext = (i - s < lightCount) ? lightPathsGlobal[lightPathBase + i - s] : vCam;
        
        // Calculate probability ratio
        currentRatio *= ComputeProbabilityRatio(vCam, vNext, vPrev);
        pathProbs[i] = currentRatio;
    }
    
    // Calculate ratios for techniques with more eye vertices (s-1, s-2, ...)
    currentRatio = 1.0;
    for (int i = s - 1; i >= 0 && i < MAX_PATH_TECHNIQUES; i--) {
        // Get the vertices involved in this transition
        Vertex vLight = lightPathsGlobal[lightPathBase + s - i - 1];
        Vertex vPrev = (s - i - 2 >= 0) ? lightPathsGlobal[lightPathBase + s - i - 2] : vLight;
        Vertex vNext = (s - i - 1 < camCount) ? cameraPathsGlobal[camPathBase + s - i - 1] : vLight;
        
        // Calculate probability ratio
        currentRatio *= ComputeProbabilityRatio(vLight, vNext, vPrev);
        pathProbs[i] = currentRatio;
    }
}

// Connects all vertices between camera and light paths, not just endpoints
vec3 ConnectAllPaths(int camPathBase, int lightPathBase, int camDepth, int lightDepth, inout vec2 seed) {
    vec3 totalContribution = vec3(0.0);
    float pathProbs[MAX_PATH_TECHNIQUES];

    Vertex cameraPathEnd = cameraPathsGlobal[camPathBase + camDepth - 1];
    Vertex lightPathEnd = lightPathsGlobal[lightPathBase + lightDepth - 1];   
    
    Ray skyRay;
    skyRay.origin = camera.position;
    skyRay.direction = normalize(cameraPathEnd.position - camera.position);
    Material hitMaterial = GetMaterial(cameraPathEnd.objIndex, cameraPathEnd.objType, skyRay);
        
    if (cameraPathEnd.emission.x > 0.0 && camDepth > 1) {
        // Calculate path probabilities for this path
        CalculatePathProbabilities(camPathBase, camDepth, lightPathBase, 0, pathProbs);
            
        // Compute MIS weight (use 0 for s=0 technique index)
        float weight = ComputeMISWeight(pathProbs, 0, camDepth + 1, 2); // beta=2 for power heuristic
            
        // Add contribution
        totalContribution +=  cameraPathEnd.emission * weight;
    }
    // Early out if either path is invalid
    if (all(equal(cameraPathEnd.throughput, vec3(0.0))) || all(equal(lightPathEnd.throughput, vec3(0.0)))) {
        return totalContribution;
    }
    
    // Connect each camera vertex with each light vertex
    for (int s = 2; s <= camDepth; s++) {
        for (int t = 1; t <= lightDepth; t++) {

            Vertex cameraPath = cameraPathsGlobal[camPathBase + s - 1];
            Vertex lightPath = lightPathsGlobal[lightPathBase + t - 1];

            // Skip invalid combinations (need at least one vertex from each path)
            Ray camRay, lightRay;
            camRay.origin = camera.position;
            camRay.direction = normalize(cameraPath.position - camera.position);
    
            lightRay.origin = camera.position;
            lightRay.direction = normalize(lightPath.position - camera.position);
    
            // Get materials at each endpoint
            Material cMat = GetMaterial(cameraPath.objIndex, cameraPath.objType, camRay);
            Material lMat = GetMaterial(lightPath.objIndex, lightPath.objType, lightRay);
    
            // Skip if either endpoint is specular (cannot be connected)
            if (cMat.specularProbability.x > 0.0 || lMat.specularProbability.x > 0.0 ||
                cMat.isTranslucent != 0 || lMat.isTranslucent != 0) {
                return totalContribution;
            }
    
            // Handle sky connections
            float skyDistance = 10000.0;

            bool isSkyLightCam = length(cameraPath.position - camera.position) > skyDistance * 0.9;
            if(isSkyLightCam) continue;

            // Regular connection between diffuse vertices
            vec3 connectionDir = normalize(lightPath.position - cameraPath.position);
            float distance = length(lightPath.position - cameraPath.position);
        
            float cosCam = max(0.0, dot(cameraPath.normal, connectionDir));
            float cosLight = max(0.0, dot(lightPath.normal, -connectionDir));
        
            if (cosCam > 0.0 && cosLight > 0.0) {
                bool isVisible = FastVisibilityTest(cameraPath.position, lightPath.position);
            
                if (isVisible) {
                    // Calculate BRDFs
                    vec3 brdfCam = cMat.diffuseColor / M_PI;
                    vec3 brdfLight = lMat.diffuseColor / M_PI;
                
                    // Geometric factor
                    float G = cosCam * cosLight / (distance * distance);
                
                    // Use a simplified MIS weight (approximation)
                    CalculatePathProbabilities(camPathBase, t+1, lightPathBase, s+1, pathProbs);
            
                    int k = s + t;  // Path length
                    // Compute MIS weight using power heuristic (beta=2)
                    float weight = ComputeMISWeight(pathProbs, s, k+2, 2);
                
                    // Connection contribution
                    vec3 connection = lightPath.emission * (cameraPath.throughput + cameraPath.emission) * brdfCam * brdfLight * G;
                    totalContribution += connection * weight;
                }
            }  
        }
    }
    
    return totalContribution;
}


// Simplified bidirectional path tracing
vec3 BidirectionalTrace(vec3 rayDir, inout vec2 seed) {

    // Calculate this thread's offset in the global buffers
    int globalWidth = int(gl_NumWorkGroups.x * LOCAL_SIZE_X);
    int threadIndex = int(gl_GlobalInvocationID.x + gl_GlobalInvocationID.y * globalWidth);
    
    // Calculate base indices for this thread's paths in the global buffers
    int camPathBase = threadIndex * MAX_PATH_LENGTH;
    int lightPathBase = threadIndex * MAX_PATH_LENGTH;

    // Generate camera path
    int camDepth = TraceCameraPath(rayDir, LENSSUBPATHS, camPathBase, seed);
    
    // Generate light path
    int lightDepth = TraceLightPath(seed, LIGHTSUBPATHS, lightPathBase);
    // Connect endpoints and return the contribution
    return ConnectAllPaths(camPathBase, lightPathBase, camDepth, lightDepth, seed);
}
///////////////////////////////
//  SCREEN COORDINATE HELPERS  //
///////////////////////////////

vec2 rayToUV(vec3 rayDir, vec3 cameraForward, float tanHalfFovY, float aspect) {
    vec3 F = normalize(cameraForward);
    vec3 R = normalize(cross(F, vec3(0, 1, 0)));
    vec3 U = cross(R, F);
    float x_cam = dot(rayDir, R);
    float y_cam = dot(rayDir, U);
    float z_cam = dot(rayDir, F);
    float tanHalfFovX = tanHalfFovY * aspect;
    float ndc_x = x_cam / (z_cam * tanHalfFovX);
    float ndc_y = y_cam / (z_cam * tanHalfFovY);
    return vec2((ndc_x + 1.0) * 0.5, (ndc_y + 1.0) * 0.5);
}

ivec2 rayToPixel(vec3 rayDir, vec3 cameraForward, float tanHalfFovY, float aspect, vec2 dims) {
    vec2 uv = rayToUV(rayDir, cameraForward, tanHalfFovY, aspect);
    int x = int(uv.x * float(dims.x));
    int y = int(uv.y * float(dims.y));
    return ivec2(x, y);
}

vec2 rayToNDC(vec3 rayDir, vec3 cameraForward, float tanHalfFovY, float aspect) {
    vec3 F = normalize(cameraForward);
    vec3 R = normalize(cross(F, vec3(0, 1, 0)));
    vec3 U = cross(R, F);
    float x_cam = dot(rayDir, R);
    float y_cam = dot(rayDir, U);
    float z_cam = dot(rayDir, F);
    float tanHalfFovX = tanHalfFovY * aspect;
    float ndc_x = (x_cam / z_cam) / tanHalfFovX;
    float ndc_y = (y_cam / z_cam) / tanHalfFovY;
    return vec2(ndc_x, ndc_y);
}

///////////////////////////////
//        MAIN FUNCTION      //
///////////////////////////////

float luminance(vec3 c, bool clampOut = true){
    return dot(clampOut ? clamp(c, 0, 1) : c, vec3(0.2126, 0.7152, 0.0722));
}

void main() {
    // Setup common values.
    ivec2 pixel_coords = ivec2(gl_GlobalInvocationID.xy);
    ivec2 dims = imageSize(screen);
    ivec2 workGroup = ivec2(gl_WorkGroupID.xy);
    ivec2 localThread = ivec2(gl_LocalInvocationID.xy);

    float u = (float(pixel_coords.x + 0.5) / float(dims.x)) * 2.0 - 1.0;
    float v = (float(pixel_coords.y + 0.5) / float(dims.y)) * 2.0 - 1.0;
    float aspectRatio = float(dims.x) / float(dims.y);
    u *= aspectRatio;

    float fovTan = tan(radians(camera.fov.x) * 0.5);
    vec3 forward = normalize(camera.direction);
    vec3 right = normalize(cross(forward, vec3(0, 1, 0)));
    vec3 up = cross(right, forward);

    // Initialize mutation state.
    vec2 currentState = vec2(
        localThread.y * 0.15663347 + uTime * 0.35663347 - v * 0.2663347,
        localThread.x * 0.45663347 + Frame * 0.45663347 - uTime * 0.45663347 + u * 0.45663347
    ) * 0.045663347;
    vec3 currentSample = vec3(0.0);

    // --- Compile-Time Branch Based on Render Mode ---
    #if defined(RENDER_MODE_0)
        // RENDER_MODE_0: Simple path tracing with multiple rays.
        {
            currentState = vec2(
                    fract(u * 12.9898 + v * 78.233 + Frame * 1.234 + uTime * 7.7191),
                    fract(u * 39.346 + v * 11.798 + Frame * 3.456 + uTime * 5.1352)
                );
            vec3 rayDir = normalize(forward + u * fovTan * right + v * fovTan * up);
            Ray ray;
            ray.origin = camera.position;
            ray.direction = rayDir;
            vec3 totalSample = vec3(0.0);
            vec2 stateCopy = currentState;
            for (int i = 0; i < NumberOfRays; i++) {
                vec2 defocusJitter = RandomPointInCircle(stateCopy) * DefocusStrength / dims.x;
                vec3 rayOrigin = camera.position + right * defocusJitter.x + up * defocusJitter.y;
                vec3 focusPoint = camera.position + rayDir * FocusDistance;
                vec2 jitter = RandomPointInCircle(stateCopy) * DivergeStrength / dims.x;
                vec3 jitteredFocusPoint = focusPoint + right * jitter.x + up * jitter.y;
                ray.origin = rayOrigin;
                ray.direction = normalize(jitteredFocusPoint - rayOrigin);
                totalSample += FullTrace(ray, stateCopy);
                stateCopy = vec2(rand(stateCopy), rand(stateCopy));
            }
            currentSample = totalSample / float(NumberOfRays + 1);
        }
    #elif defined(RENDER_MODE_1)
        // RENDER_MODE_1: Metropolis sampling mode.
        {
            // Calculate the size of each image region based on the workgroup and dispatch sizes.
            float imageRegionSizeX = 1.0 / float(LOCAL_SIZE_X * METROPLIS_DISPATCH_X);
            float imageRegionSizeY = 1.0 / float(LOCAL_SIZE_Y * METROPLIS_DISPATCH_Y);

            // Calculate the offset of the current thread's image region.
            float imageRegionOffsetX = localThread.x * imageRegionSizeX + workGroup.x * imageRegionSizeX * LOCAL_SIZE_X;
            float imageRegionOffsetY = localThread.y * imageRegionSizeY + workGroup.y * imageRegionSizeY * LOCAL_SIZE_Y;

            // Use the pixel coordinates as the global burn-in index.
            ivec2 globalBurnIn = pixel_coords; 

            // Burn-in phase: perform additional sampling until a non-zero luminance is achieved, or a maximum number of tries.
            if (Frame == 0) {
                vec3 burnInSampleColor = vec3(0.0);
                float burnInSampleLum = 0.0;

                int tries = 0;
                int burnIns = 0;
                // Create a copy of the mutation state.
                vec2 stateCopy = currentState;

                // Repeat sampling until we get a non-zero luminance or we reach 10 tries.
                while(burnInSampleLum == 0 && tries < 10) {
                    for (int i = 0; i < BurnInSamples; i++) {
                        // Update the state copy with a small variation.
                        stateCopy = currentState + vec2(
                            fract(u * 12.9898 + v * 78.233 + Frame * 1.234 + uTime * 7.7191 + i * 0.8443),
                            fract(u * 39.346 + v * 11.798 + Frame * 3.456 + uTime * 5.1352 - i * 0.3565)
                        );

                        // Generate a random ray direction.
                        double u_rand = rand(stateCopy) * 2.0 - 1.0;
                        double v_rand = rand(stateCopy) * 2.0 - 1.0;
                        u_rand *= aspectRatio;

                        vec3 rayDir = vec3(normalize(forward + u_rand * fovTan * right + v_rand * fovTan * up));
                        Ray ray;
                        ray.origin = camera.position;
                        ray.direction = rayDir;

                        // Trace the ray and accumulate the sample color.
                        vec3 sampleColor = BidirectionalTrace(ray, stateCopy);
                        burnInSampleColor += sampleColor;
                        burnInSampleLum += luminance(sampleColor, false); // Compute luminance.
                        burnIns++;
                    }
                    tries++;
                }

                // Average the burn-in samples.
                burnInSampleColor /= float(burnIns);
                burnInSampleLum /= float(burnIns);

                // Load the previously accumulated burn-in data from the averageScreen.
                vec4 oldBurnIn = imageLoad(averageScreen, ivec2(0, 0));
                int oldCount = int(oldBurnIn.a);
                // Compute new average luminance.
                float rgb = (oldBurnIn.r * float(oldCount) + burnInSampleLum) / (float(oldCount) + 1.0f);

                // Store the updated average luminance back to averageScreen.
                imageStore(averageScreen, ivec2(0, 0), vec4(rgb, rgb, rgb, oldCount + 1));
            }
            else {
                // In subsequent frames, compute the new UV coordinates for mutation.
                vec2 currentUV;
                if (Frame == 1) {
                    // If this is the first frame, compute a new UV using the random state.
                    double x = rand(currentState) * imageRegionSizeX + imageRegionOffsetX;
                    double y = rand(currentState) * imageRegionSizeY + imageRegionOffsetY;
                    vec2 randomSample = vec2(x, y);

                    double u_random = randomSample.x * 2.0 - 1.0;
                    double v_random = randomSample.y * 2.0 - 1.0;
                    u_random *= aspectRatio;
                    currentUV = vec2(u_random, v_random);
                } else {
                    // Otherwise, load the UV from the metroDir texture.
                    currentUV = imageLoad(metroDir, globalBurnIn).rg;
                }

                // Reinitialize the mutation state based on the current UV and time.
                currentState =  vec2(
                    fract(u * 12.9898 + v * 78.233 + Frame * 1.234 + uTime * 7.7191),
                    fract(u * 39.346 + v * 11.798 + Frame * 3.456 + uTime * 5.1352)
                );

                // Compute the ray direction from the updated UV.
                vec3 rayDir = normalize(forward + currentUV.x * fovTan * right + currentUV.y * fovTan * up);
                Ray ray;
                ray.origin = camera.position;
                ray.direction = rayDir;
                // Trace the ray or load the previous sample depending on the frame.
                if (Frame == 1) {
                    currentSample = FullTrace(ray, currentState);
                } else {
                    currentSample = FullTrace(ray, currentState);
                }

                // Get the current average luminance from the averageScreen.
                float b = imageLoad(averageScreen, ivec2(0, 0)).r;
                if (b == 0.0) return;
                dvec2 stateCopy = currentState;  // Create a copy for mutation.

                // Mutation loop: perform Metropolis mutations.
                for (int i = 0; i < NumberOfMutations; i++) {
                    vec3 candidateSample;
                    vec2 candidateState;
                    Ray candidateRay;

                    // Perturb the current UV coordinate using an exponential radial lens perturbation.
                    stateCopy = currentState * 0.389725 +  dvec2(
                    fract(currentUV.x * 0.9898 + currentUV.y * 0.233 + Frame * 0.234 + uTime * 0.7191),
                    fract(currentUV.x * 0.346 + currentUV.y * 0.798 + Frame * 0.456 + uTime * 0.1352)
                    );

                    // Generate a candidate UV via lens perturbation.
                    MutationResults results = lensPerturbation(currentUV, aspectRatio, 1.0 / 10240.0, 1.0 / 64.0, stateCopy);
                    vec2 candidateUV = results.uv;

                    // Recompute the candidate ray direction from the mutated UV.
                    vec3 candidateRayDir = normalize(forward + candidateUV.x * fovTan * right + candidateUV.y * fovTan * up);
                    candidateRay.origin = camera.position;
                    candidateRay.direction = candidateRayDir;
                    candidateState = candidateUV;
                    candidateState +=  vec2(
                        fract(Frame * 0.234 + uTime * 0.7191),
                        fract(Frame * 0.456 + uTime * 0.1352)
                    );

                    // Trace the candidate ray.
                    candidateSample = FullTrace(candidateRay, candidateState);

                    // Compute the luminance of the current and candidate samples.
                    float currentLumNC = luminance(currentSample, false);
                    float candidateLumNC = luminance(candidateSample, false);

                    float currentLumC = luminance(currentSample, true);
                    float candidateLumC = luminance(candidateSample, true);
                    // Determine the acceptance probability.
                    float acceptance = min(1.0, candidateLumC / (currentLumC + 1e-4));

                    // Compute pixel coordinates for the current and candidate rays.
                    ivec2 curPixel = rayToPixel(ray.direction, forward, fovTan, aspectRatio, dims);
                    ivec2 nextPixel = rayToPixel(candidateRay.direction, forward, fovTan, aspectRatio, dims);

                    // Load the current accumulated colors from the oldScreen.
                    vec4 curOld = imageLoad(oldScreen, curPixel);
                    vec4 nextOld = imageLoad(oldScreen, nextPixel);

                    barrier();
                    memoryBarrier();

                    int countOld = int(curOld.a);
                    int countNext = int(nextOld.a);

                    // Compute weights for blending based on the acceptance probability.
                    float curweight = (1.0 - acceptance) / ((currentLumC + 1e-4) / (b) + pLargeStep);
                    float nextWeight = (acceptance + results.large) / ((candidateLumC + 1e-4) / (b) + pLargeStep);

                    // Prepare the new color values.
                    vec4 currColor = vec4(currentSample, 1) * (1.0 - acceptance);
                    vec4 nextColor = vec4(candidateSample, 1) * acceptance;

                    vec4 weightedRGB = (curOld * float(countOld) + currColor) / (float(countOld) + 1.0f);
            
                    vec4 weightedRGBNext = (nextOld * float(countNext) + nextColor) / (float(countNext) + 1.0f);

                    barrier();
                    memoryBarrier();

                    // Metropolis acceptance step:
                    if (rand(candidateState) < acceptance) {
                        // Accept the candidate sample.
                        currentState = candidateState;
                        currentSample = candidateSample;
                        ray = candidateRay;
                        currentUV = candidateUV;
                    } else {
                        // Otherwise, store the candidate sample at the next pixel.
                        //imageStore(screen, nextPixel, vec4(weightedRGBNext.rgb, countNext + 1.0));
                    }
                    imageStore(screen, curPixel, vec4(weightedRGB.rgb, countOld + 1.0));
                    imageStore(screen, nextPixel, vec4(weightedRGBNext.rgb, countNext + 1.0));
                    
                    barrier();
                    memoryBarrier();
                }


                // Store the final mutated UV and sample color for reuse in subsequent frames.
                imageStore(metroDir, globalBurnIn, vec4(currentUV, 1, 1));
                imageStore(metroSample, globalBurnIn, vec4(currentSample, 1));
            }
            return;
        }
    #elif defined(RENDER_MODE_2)
        // RENDER_MODE_2: Bidirectional sampling mode.
        {
            // Initialize state with good variance for this pixel
            vec2 stateCopy = vec2(
                fract(u * 12.9898 + v * 78.233 + Frame * 1.234 + uTime * 7.7191),
                fract(u * 39.346 + v * 11.798 + Frame * 3.456 + uTime * 5.1352)
            );
        
            // Calculate ray direction for this pixel
            vec3 rayDir = normalize(forward + u * fovTan * right + v * fovTan * up);
        
            // Apply defocus blur if enabled
            if (DefocusStrength > 0.0) {
                vec2 defocusJitter = RandomPointInCircle(stateCopy) * DefocusStrength / dims.x;
                vec3 rayOrigin = camera.position + right * defocusJitter.x + up * defocusJitter.y;
                vec3 focusPoint = camera.position + rayDir * FocusDistance;
                vec2 jitter = RandomPointInCircle(stateCopy) * DivergeStrength / dims.x;
                vec3 jitteredFocusPoint = focusPoint + right * jitter.x + up * jitter.y;
                rayDir = normalize(jitteredFocusPoint - rayOrigin);
            }
        
            // Perform bidirectional path tracing for this pixel
            currentSample = BidirectionalTrace(rayDir, stateCopy);
        } 
    // --- Branch Based on Render Mode ---
    #elif defined(RENDER_MODE_3)
        // NEE Mode: Generate ray with defocus blur if enabled
        vec3 rayDir = normalize(forward + u * fovTan * right + v * fovTan * up);
        
        if (DefocusStrength > 0.0) {
            vec2 defocusJitter = RandomPointInCircle(currentState) * DefocusStrength / dims.x;
            vec3 rayOrigin = camera.position + right * defocusJitter.x + up * defocusJitter.y;
            vec3 focusPoint = camera.position + rayDir * FocusDistance;
            vec2 jitter = RandomPointInCircle(currentState) * DivergeStrength / dims.x;
            vec3 jitteredFocusPoint = focusPoint + right * jitter.x + up * jitter.y;
            rayDir = normalize(jitteredFocusPoint - rayOrigin);
        }
        
        // Create ray and trace with NEE
        Ray ray;
        ray.origin = camera.position;
        ray.direction = rayDir;
        
        currentSample = NEETrace(ray, currentState);
     #endif
    // Final accumulation and output.
    vec3 old = imageLoad(oldScreen, pixel_coords).rgb;
    float weight = 1.0 / float(Frame + 1.0);
    vec3 average = clamp(old * (1.0 - weight) + currentSample * weight, 0.0, 1.0);
    imageStore(screen, pixel_coords, vec4(average, 1.0));
}